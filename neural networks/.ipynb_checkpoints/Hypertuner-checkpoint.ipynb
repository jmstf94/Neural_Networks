{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ae900e-3091-4569-baba-a04ff40b8639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer, TFAutoModel\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import metrics\n",
    "\n",
    "from simpletransformers.language_representation import RepresentationModel\n",
    "\n",
    "from TweetDataReport import datasplit, print_tweet_report, check_relevance_balance, datasplit_new\n",
    "\n",
    "import time\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "from hyperopt import hp, fmin, tpe , pyll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786a75d6-fdaa-48a7-83da-5345dd767442",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version:3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]\n",
      "TensorFlow Version: 2.10.0\n",
      "GPU is available\n",
      "CUDA Version: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Python Version:\" + sys.version)\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "if tf.test.gpu_device_name():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is NOT available\")\n",
    "print(\"CUDA Version:\", tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167ebd18-9ca0-4979-b808-b340e826f1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file = 'data/italian/00-dirty_dataset/feature_extractions/bert/dbmdz_bert-base-italian-cased.pkl'\n",
    "\n",
    "# with open(file, \"rb\") as file:\n",
    "#     WF = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4ace83-271d-496a-853e-49a6949c7a83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_names</th>\n",
       "      <th>data_types</th>\n",
       "      <th>shape_len</th>\n",
       "      <th>unique_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reps</td>\n",
       "      <td>&lt;class 'numpy.ndarray'&gt;</td>\n",
       "      <td>(1, 768)</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relevance</td>\n",
       "      <td>&lt;class 'numpy.int64'&gt;</td>\n",
       "      <td>()</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  column_names               data_types shape_len  unique_values\n",
       "0         reps  <class 'numpy.ndarray'>  (1, 768)           1892\n",
       "1    relevance    <class 'numpy.int64'>        ()              2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print_tweet_report(WF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f40341-808d-48e9-8d9f-08664434fed3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>count</th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1258</td>\n",
       "      <td>66.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>634</td>\n",
       "      <td>33.51%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevance  count balance\n",
       "0          0   1258  66.49%\n",
       "1          1    634  33.51%"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check_relevance_balance(WF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67613ad0-b81b-465a-b5cf-3b5bd7064ee5",
   "metadata": {},
   "source": [
    "## DATA REP PREPARATION (BERT-GPTdone/roberta didn't work due to the same error in every language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d931c4a0-b444-47cc-81b2-1b06e1b9f265",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForTextRepresentation were not initialized from the model checkpoint at GroNLP/gpt2-small-italian-embeddings and are newly initialized: ['transformer.gpt2.h.3.mlp.c_proj.bias', 'transformer.gpt2.h.2.mlp.c_proj.weight', 'transformer.gpt2.h.3.ln_1.bias', 'transformer.gpt2.h.5.ln_2.bias', 'transformer.gpt2.h.0.attn.c_attn.bias', 'transformer.gpt2.h.4.mlp.c_proj.weight', 'transformer.gpt2.h.2.mlp.c_proj.bias', 'transformer.gpt2.h.11.ln_2.bias', 'transformer.gpt2.h.10.attn.c_proj.bias', 'transformer.gpt2.h.11.ln_2.weight', 'transformer.gpt2.h.8.mlp.c_fc.weight', 'transformer.gpt2.ln_f.weight', 'transformer.gpt2.h.8.attn.c_attn.bias', 'transformer.gpt2.h.3.attn.c_attn.bias', 'transformer.gpt2.h.11.attn.c_proj.weight', 'transformer.gpt2.h.8.attn.c_proj.weight', 'transformer.gpt2.h.4.attn.c_attn.weight', 'transformer.gpt2.h.4.ln_2.bias', 'transformer.gpt2.h.7.attn.c_proj.weight', 'transformer.gpt2.h.9.ln_2.bias', 'transformer.gpt2.h.3.attn.c_attn.weight', 'transformer.gpt2.h.11.ln_1.bias', 'transformer.gpt2.h.5.attn.c_proj.bias', 'transformer.gpt2.h.8.ln_2.bias', 'transformer.gpt2.h.0.ln_2.bias', 'transformer.gpt2.h.10.mlp.c_proj.bias', 'transformer.gpt2.h.0.attn.c_attn.weight', 'transformer.gpt2.h.9.mlp.c_proj.bias', 'transformer.gpt2.h.1.mlp.c_fc.bias', 'transformer.gpt2.h.6.ln_1.weight', 'transformer.gpt2.h.9.attn.c_proj.bias', 'transformer.gpt2.h.7.ln_1.bias', 'transformer.gpt2.h.1.attn.c_attn.weight', 'transformer.gpt2.h.11.mlp.c_proj.bias', 'transformer.gpt2.h.1.attn.c_proj.weight', 'transformer.gpt2.h.7.attn.c_proj.bias', 'transformer.gpt2.h.5.mlp.c_fc.weight', 'transformer.gpt2.h.5.attn.c_proj.weight', 'transformer.gpt2.h.1.mlp.c_fc.weight', 'transformer.gpt2.h.10.mlp.c_fc.bias', 'transformer.gpt2.h.9.mlp.c_fc.weight', 'transformer.gpt2.h.4.attn.c_proj.weight', 'transformer.gpt2.h.3.ln_2.weight', 'transformer.gpt2.h.8.mlp.c_fc.bias', 'transformer.gpt2.h.7.attn.c_attn.weight', 'transformer.gpt2.h.9.mlp.c_fc.bias', 'transformer.gpt2.h.7.attn.c_attn.bias', 'transformer.gpt2.h.1.ln_2.weight', 'transformer.gpt2.h.11.mlp.c_fc.weight', 'transformer.gpt2.h.3.attn.c_proj.bias', 'transformer.gpt2.h.2.mlp.c_fc.bias', 'transformer.gpt2.h.3.ln_2.bias', 'transformer.gpt2.h.4.ln_1.bias', 'transformer.gpt2.h.5.mlp.c_proj.bias', 'transformer.gpt2.h.7.mlp.c_fc.bias', 'transformer.gpt2.h.0.ln_2.weight', 'transformer.gpt2.h.8.ln_1.bias', 'transformer.gpt2.h.9.ln_2.weight', 'transformer.gpt2.h.8.attn.c_proj.bias', 'transformer.gpt2.h.3.mlp.c_fc.bias', 'transformer.gpt2.wte.weight', 'transformer.gpt2.h.2.ln_2.bias', 'transformer.gpt2.h.6.attn.c_proj.weight', 'transformer.gpt2.h.6.ln_2.bias', 'transformer.gpt2.h.0.ln_1.bias', 'transformer.gpt2.h.10.attn.c_proj.weight', 'transformer.gpt2.h.5.attn.c_attn.bias', 'transformer.gpt2.h.2.attn.c_attn.bias', 'transformer.gpt2.wpe.weight', 'transformer.gpt2.h.8.ln_1.weight', 'transformer.gpt2.h.8.ln_2.weight', 'transformer.gpt2.h.10.mlp.c_fc.weight', 'transformer.gpt2.h.11.attn.c_attn.weight', 'transformer.gpt2.h.5.mlp.c_fc.bias', 'transformer.gpt2.ln_f.bias', 'transformer.gpt2.h.6.attn.c_attn.weight', 'transformer.gpt2.h.9.attn.c_attn.weight', 'transformer.gpt2.h.0.attn.c_proj.weight', 'transformer.gpt2.h.5.attn.c_attn.weight', 'transformer.gpt2.h.10.attn.c_attn.weight', 'transformer.gpt2.h.8.mlp.c_proj.weight', 'transformer.gpt2.h.7.mlp.c_proj.weight', 'transformer.gpt2.h.4.attn.c_proj.bias', 'transformer.gpt2.h.6.attn.c_attn.bias', 'transformer.gpt2.h.5.ln_1.bias', 'transformer.gpt2.h.5.mlp.c_proj.weight', 'transformer.gpt2.h.4.mlp.c_fc.weight', 'transformer.gpt2.h.6.mlp.c_proj.weight', 'transformer.gpt2.h.4.mlp.c_proj.bias', 'transformer.gpt2.h.9.attn.c_attn.bias', 'transformer.gpt2.h.3.mlp.c_proj.weight', 'transformer.gpt2.h.9.mlp.c_proj.weight', 'transformer.gpt2.h.0.mlp.c_proj.weight', 'transformer.gpt2.h.2.mlp.c_fc.weight', 'transformer.gpt2.h.11.mlp.c_fc.bias', 'transformer.gpt2.h.11.attn.c_proj.bias', 'transformer.gpt2.h.4.attn.c_attn.bias', 'transformer.gpt2.h.1.mlp.c_proj.bias', 'transformer.gpt2.h.1.attn.c_proj.bias', 'transformer.gpt2.h.1.ln_1.weight', 'transformer.gpt2.h.9.ln_1.bias', 'transformer.gpt2.h.2.ln_1.bias', 'transformer.gpt2.h.1.mlp.c_proj.weight', 'transformer.gpt2.h.6.ln_1.bias', 'transformer.gpt2.h.5.ln_2.weight', 'transformer.gpt2.h.6.mlp.c_fc.weight', 'transformer.gpt2.h.0.mlp.c_proj.bias', 'transformer.gpt2.h.11.attn.c_attn.bias', 'transformer.gpt2.h.11.ln_1.weight', 'transformer.gpt2.h.7.ln_2.bias', 'transformer.gpt2.h.1.ln_2.bias', 'transformer.gpt2.h.10.ln_2.weight', 'transformer.gpt2.h.2.attn.c_proj.weight', 'transformer.gpt2.h.4.ln_2.weight', 'transformer.gpt2.h.10.mlp.c_proj.weight', 'transformer.gpt2.h.6.mlp.c_proj.bias', 'transformer.gpt2.h.10.attn.c_attn.bias', 'transformer.gpt2.h.0.attn.c_proj.bias', 'transformer.gpt2.h.11.mlp.c_proj.weight', 'transformer.gpt2.h.4.ln_1.weight', 'transformer.gpt2.h.6.attn.c_proj.bias', 'transformer.gpt2.h.2.attn.c_proj.bias', 'transformer.gpt2.h.3.mlp.c_fc.weight', 'transformer.gpt2.h.2.ln_2.weight', 'transformer.gpt2.h.8.attn.c_attn.weight', 'transformer.gpt2.h.1.ln_1.bias', 'transformer.gpt2.h.0.mlp.c_fc.bias', 'transformer.gpt2.h.2.attn.c_attn.weight', 'transformer.gpt2.h.10.ln_2.bias', 'transformer.gpt2.h.2.ln_1.weight', 'transformer.gpt2.h.9.ln_1.weight', 'transformer.gpt2.h.8.mlp.c_proj.bias', 'transformer.gpt2.h.3.attn.c_proj.weight', 'transformer.gpt2.h.6.ln_2.weight', 'transformer.gpt2.h.4.mlp.c_fc.bias', 'transformer.gpt2.h.1.attn.c_attn.bias', 'transformer.gpt2.h.5.ln_1.weight', 'transformer.gpt2.h.9.attn.c_proj.weight', 'transformer.gpt2.h.7.ln_1.weight', 'transformer.gpt2.h.7.ln_2.weight', 'transformer.gpt2.h.6.mlp.c_fc.bias', 'transformer.gpt2.h.10.ln_1.weight', 'transformer.gpt2.h.0.ln_1.weight', 'transformer.gpt2.h.10.ln_1.bias', 'transformer.gpt2.h.0.mlp.c_fc.weight', 'transformer.gpt2.h.7.mlp.c_fc.weight', 'transformer.gpt2.h.3.ln_1.weight', 'transformer.gpt2.h.7.mlp.c_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/italian/04-twisted_remover_with_emoticons/feature_extractions/gpt2/GroNLP_gpt2-small-italian-embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "language =  'italian'\n",
    "#language =  'spanish'\n",
    "#language =  'greek'\n",
    "\n",
    "cleanings = ['00-dirty_dataset','01-basic_remover','02-basic_remover_without_stopwords','03-basic_remover_without_stopwords_with_stemming','04-twisted_remover_with_emoticons']\n",
    "\n",
    "#case = 'bert'\n",
    "#case = 'roberta'\n",
    "case = 'gpt2'\n",
    "\n",
    "# reps_models = [\"dbmdz/bert-base-italian-uncased\",\"dbmdz/bert-base-italian-cased\",\"dbmdz/bert-base-italian-xxl-cased\",\"dbmdz/bert-base-italian-xxl-uncased\"]\n",
    "# reps_models = ['osiria/roberta-base-italian']\n",
    "reps_models = [\"GroNLP/gpt2-small-italian\",\"GroNLP/gpt2-medium-italian-embeddings\",\"GroNLP/gpt2-small-italian-embeddings\"]\n",
    "\n",
    "for combo in itertools.product(cleanings,reps_models):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    with open('data/'+ language +'/'+ combo[0] +'/data.pkl','rb') as file:\n",
    "        WF = pickle.load(file)\n",
    "    \n",
    "    pretrained_model = RepresentationModel(model_type=case,model_name=combo[1],use_cuda=False) \n",
    "    sentence_vectors = pretrained_model.encode_sentences(WF['text'], combine_strategy=\"mean\")\n",
    "    sentence_vectors = np.split(sentence_vectors,sentence_vectors.shape[0])\n",
    "    pandasseries = pd.Series(sentence_vectors)\n",
    "    WF['reps'] = pandasseries.copy()\n",
    "    data = pd.DataFrame()\n",
    "    data['reps'] = WF['reps'].copy()\n",
    "    data['relevance'] = WF['relevance'].copy()\n",
    "    \n",
    "    link = 'data/'+ language +'/'+ combo[0] +'/feature_extractions/'+case+'/'+ str(combo[1]).replace('/', '_')+'.pkl'\n",
    "    \n",
    "    print(link)\n",
    "    \n",
    "    with open(link , 'wb') as file:\n",
    "        pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4635de91-bf56-4022-8c1a-0b2bcd878d21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForTextRepresentation were not initialized from the model checkpoint at DeepESP/gpt2-spanish-medium and are newly initialized: ['transformer.gpt2.h.23.ln_2.weight', 'transformer.gpt2.h.19.attn.c_proj.bias', 'transformer.gpt2.h.3.mlp.c_fc.bias', 'transformer.gpt2.wpe.weight', 'transformer.gpt2.h.0.attn.c_attn.weight', 'transformer.gpt2.h.9.mlp.c_proj.bias', 'transformer.gpt2.h.13.attn.c_proj.weight', 'transformer.gpt2.wte.weight', 'transformer.gpt2.h.7.mlp.c_proj.weight', 'transformer.gpt2.h.18.attn.c_proj.weight', 'transformer.gpt2.h.2.ln_2.bias', 'transformer.gpt2.h.2.attn.c_proj.weight', 'transformer.gpt2.h.17.attn.c_proj.weight', 'transformer.gpt2.h.23.ln_1.bias', 'transformer.gpt2.h.6.attn.c_proj.weight', 'transformer.gpt2.h.7.mlp.c_fc.weight', 'transformer.gpt2.h.18.attn.c_attn.bias', 'transformer.gpt2.h.12.attn.c_attn.weight', 'transformer.gpt2.h.10.mlp.c_proj.bias', 'transformer.gpt2.h.12.mlp.c_proj.weight', 'transformer.gpt2.h.18.attn.c_proj.bias', 'transformer.gpt2.h.21.mlp.c_proj.bias', 'transformer.gpt2.h.5.attn.c_proj.bias', 'transformer.gpt2.h.17.ln_1.bias', 'transformer.gpt2.h.0.attn.c_proj.bias', 'transformer.gpt2.h.7.ln_1.bias', 'transformer.gpt2.h.8.ln_1.bias', 'transformer.gpt2.h.7.ln_2.bias', 'transformer.gpt2.h.2.ln_1.bias', 'transformer.gpt2.h.17.ln_2.weight', 'transformer.gpt2.h.17.mlp.c_fc.weight', 'transformer.gpt2.h.0.mlp.c_proj.bias', 'transformer.gpt2.h.22.attn.c_attn.bias', 'transformer.gpt2.h.14.ln_1.bias', 'transformer.gpt2.h.10.mlp.c_proj.weight', 'transformer.gpt2.h.0.ln_1.bias', 'transformer.gpt2.h.20.ln_1.bias', 'transformer.gpt2.h.18.mlp.c_fc.bias', 'transformer.gpt2.h.15.ln_2.bias', 'transformer.gpt2.h.14.attn.c_attn.weight', 'transformer.gpt2.h.4.ln_1.weight', 'transformer.gpt2.h.0.ln_1.weight', 'transformer.gpt2.h.1.attn.c_attn.weight', 'transformer.gpt2.h.20.attn.c_attn.weight', 'transformer.gpt2.h.9.ln_1.bias', 'transformer.gpt2.h.6.mlp.c_proj.weight', 'transformer.gpt2.h.2.attn.c_proj.bias', 'transformer.gpt2.h.9.ln_2.weight', 'transformer.gpt2.h.23.ln_2.bias', 'transformer.gpt2.h.3.attn.c_proj.weight', 'transformer.gpt2.h.23.mlp.c_proj.bias', 'transformer.gpt2.h.2.attn.c_attn.bias', 'transformer.gpt2.h.16.ln_1.weight', 'transformer.gpt2.h.13.ln_1.bias', 'transformer.gpt2.h.8.ln_1.weight', 'transformer.gpt2.h.16.attn.c_attn.weight', 'transformer.gpt2.h.18.mlp.c_proj.weight', 'transformer.gpt2.h.21.ln_2.bias', 'transformer.gpt2.h.23.mlp.c_fc.bias', 'transformer.gpt2.h.5.ln_1.bias', 'transformer.gpt2.h.13.attn.c_proj.bias', 'transformer.gpt2.h.17.mlp.c_proj.weight', 'transformer.gpt2.h.5.mlp.c_fc.bias', 'transformer.gpt2.h.0.ln_2.weight', 'transformer.gpt2.h.19.attn.c_attn.weight', 'transformer.gpt2.h.7.attn.c_attn.bias', 'transformer.gpt2.h.6.mlp.c_fc.weight', 'transformer.gpt2.h.13.ln_1.weight', 'transformer.gpt2.h.6.ln_2.weight', 'transformer.gpt2.h.21.attn.c_proj.weight', 'transformer.gpt2.h.10.ln_2.bias', 'transformer.gpt2.h.21.ln_2.weight', 'transformer.gpt2.h.3.attn.c_attn.bias', 'transformer.gpt2.h.11.mlp.c_fc.weight', 'transformer.gpt2.h.8.mlp.c_fc.weight', 'transformer.gpt2.h.14.ln_2.bias', 'transformer.gpt2.h.2.ln_2.weight', 'transformer.gpt2.h.3.mlp.c_fc.weight', 'transformer.gpt2.h.23.attn.c_attn.weight', 'transformer.gpt2.h.17.attn.c_attn.weight', 'transformer.gpt2.h.8.attn.c_proj.bias', 'transformer.gpt2.h.16.ln_1.bias', 'transformer.gpt2.h.7.mlp.c_fc.bias', 'transformer.gpt2.h.9.mlp.c_fc.bias', 'transformer.gpt2.h.3.attn.c_proj.bias', 'transformer.gpt2.h.14.attn.c_proj.bias', 'transformer.gpt2.h.6.ln_1.bias', 'transformer.gpt2.h.1.ln_1.weight', 'transformer.gpt2.h.11.ln_2.bias', 'transformer.gpt2.h.10.attn.c_attn.bias', 'transformer.gpt2.h.10.ln_2.weight', 'transformer.gpt2.h.13.attn.c_attn.weight', 'transformer.gpt2.h.18.ln_2.bias', 'transformer.gpt2.h.7.attn.c_proj.weight', 'transformer.gpt2.h.5.mlp.c_proj.weight', 'transformer.gpt2.h.11.attn.c_proj.weight', 'transformer.gpt2.h.5.ln_2.weight', 'transformer.gpt2.h.8.attn.c_attn.weight', 'transformer.gpt2.h.12.ln_2.weight', 'transformer.gpt2.h.9.mlp.c_proj.weight', 'transformer.gpt2.h.12.attn.c_attn.bias', 'transformer.gpt2.h.12.attn.c_proj.bias', 'transformer.gpt2.h.14.mlp.c_fc.bias', 'transformer.gpt2.h.4.attn.c_attn.weight', 'transformer.gpt2.h.17.mlp.c_proj.bias', 'transformer.gpt2.h.22.ln_1.weight', 'transformer.gpt2.h.7.attn.c_proj.bias', 'transformer.gpt2.h.22.mlp.c_proj.bias', 'transformer.gpt2.h.11.attn.c_proj.bias', 'transformer.gpt2.h.6.mlp.c_fc.bias', 'transformer.gpt2.h.6.attn.c_attn.bias', 'transformer.gpt2.h.14.ln_1.weight', 'transformer.gpt2.h.9.ln_2.bias', 'transformer.gpt2.h.15.ln_1.weight', 'transformer.gpt2.h.19.mlp.c_fc.weight', 'transformer.gpt2.h.3.ln_2.bias', 'transformer.gpt2.h.4.mlp.c_fc.bias', 'transformer.gpt2.h.17.attn.c_attn.bias', 'transformer.gpt2.h.20.ln_2.weight', 'transformer.gpt2.ln_f.weight', 'transformer.gpt2.h.17.ln_2.bias', 'transformer.gpt2.h.1.ln_2.bias', 'transformer.gpt2.h.13.mlp.c_proj.weight', 'transformer.gpt2.h.7.attn.c_attn.weight', 'transformer.gpt2.h.4.attn.c_proj.bias', 'transformer.gpt2.h.23.attn.c_attn.bias', 'transformer.gpt2.h.22.ln_2.bias', 'transformer.gpt2.h.4.mlp.c_fc.weight', 'transformer.gpt2.h.18.ln_1.bias', 'transformer.gpt2.h.7.ln_2.weight', 'transformer.gpt2.h.9.ln_1.weight', 'transformer.gpt2.h.12.ln_1.weight', 'transformer.gpt2.h.13.mlp.c_proj.bias', 'transformer.gpt2.h.14.mlp.c_proj.weight', 'transformer.gpt2.h.5.attn.c_attn.weight', 'transformer.gpt2.h.5.mlp.c_proj.bias', 'transformer.gpt2.h.12.attn.c_proj.weight', 'transformer.gpt2.h.11.mlp.c_proj.weight', 'transformer.gpt2.h.0.mlp.c_fc.weight', 'transformer.gpt2.h.7.ln_1.weight', 'transformer.gpt2.h.4.ln_2.bias', 'transformer.gpt2.h.7.mlp.c_proj.bias', 'transformer.gpt2.h.13.mlp.c_fc.weight', 'transformer.gpt2.h.19.ln_2.bias', 'transformer.gpt2.h.15.ln_2.weight', 'transformer.gpt2.h.1.attn.c_proj.weight', 'transformer.gpt2.h.18.mlp.c_fc.weight', 'transformer.gpt2.h.11.ln_1.bias', 'transformer.gpt2.h.3.ln_1.weight', 'transformer.gpt2.h.21.attn.c_attn.weight', 'transformer.gpt2.h.8.mlp.c_proj.bias', 'transformer.gpt2.h.1.ln_2.weight', 'transformer.gpt2.h.22.mlp.c_fc.bias', 'transformer.gpt2.h.0.ln_2.bias', 'transformer.gpt2.h.16.attn.c_proj.bias', 'transformer.gpt2.h.10.ln_1.bias', 'transformer.gpt2.h.8.ln_2.bias', 'transformer.gpt2.h.9.attn.c_proj.weight', 'transformer.gpt2.h.10.mlp.c_fc.bias', 'transformer.gpt2.h.4.ln_1.bias', 'transformer.gpt2.h.15.mlp.c_fc.weight', 'transformer.gpt2.h.18.ln_2.weight', 'transformer.gpt2.h.22.attn.c_proj.bias', 'transformer.gpt2.h.23.mlp.c_proj.weight', 'transformer.gpt2.h.16.mlp.c_proj.bias', 'transformer.gpt2.h.13.mlp.c_fc.bias', 'transformer.gpt2.h.2.mlp.c_fc.weight', 'transformer.gpt2.h.12.mlp.c_fc.bias', 'transformer.gpt2.h.8.attn.c_attn.bias', 'transformer.gpt2.h.6.mlp.c_proj.bias', 'transformer.gpt2.h.21.attn.c_attn.bias', 'transformer.gpt2.h.17.ln_1.weight', 'transformer.gpt2.h.13.attn.c_attn.bias', 'transformer.gpt2.h.15.ln_1.bias', 'transformer.gpt2.h.21.mlp.c_fc.bias', 'transformer.gpt2.h.23.attn.c_proj.weight', 'transformer.gpt2.h.11.attn.c_attn.bias', 'transformer.gpt2.h.1.mlp.c_proj.weight', 'transformer.gpt2.h.14.attn.c_proj.weight', 'transformer.gpt2.h.4.ln_2.weight', 'transformer.gpt2.h.9.attn.c_attn.bias', 'transformer.gpt2.h.16.ln_2.weight', 'transformer.gpt2.h.19.ln_2.weight', 'transformer.gpt2.h.1.mlp.c_fc.bias', 'transformer.gpt2.h.20.attn.c_proj.weight', 'transformer.gpt2.h.22.ln_1.bias', 'transformer.gpt2.h.6.attn.c_attn.weight', 'transformer.gpt2.h.4.attn.c_attn.bias', 'transformer.gpt2.h.8.mlp.c_fc.bias', 'transformer.gpt2.h.18.attn.c_attn.weight', 'transformer.gpt2.h.21.mlp.c_proj.weight', 'transformer.gpt2.h.22.mlp.c_proj.weight', 'transformer.gpt2.h.9.mlp.c_fc.weight', 'transformer.gpt2.h.20.attn.c_attn.bias', 'transformer.gpt2.h.13.ln_2.weight', 'transformer.gpt2.h.2.mlp.c_proj.bias', 'transformer.gpt2.h.21.ln_1.weight', 'transformer.gpt2.h.2.mlp.c_fc.bias', 'transformer.gpt2.h.2.ln_1.weight', 'transformer.gpt2.h.12.ln_2.bias', 'transformer.gpt2.h.20.ln_1.weight', 'transformer.gpt2.h.0.attn.c_proj.weight', 'transformer.gpt2.h.12.mlp.c_fc.weight', 'transformer.gpt2.h.11.mlp.c_proj.bias', 'transformer.gpt2.h.10.mlp.c_fc.weight', 'transformer.gpt2.h.8.ln_2.weight', 'transformer.gpt2.h.20.attn.c_proj.bias', 'transformer.gpt2.h.20.ln_2.bias', 'transformer.gpt2.h.14.mlp.c_fc.weight', 'transformer.gpt2.h.15.attn.c_attn.weight', 'transformer.gpt2.h.0.attn.c_attn.bias', 'transformer.gpt2.h.1.mlp.c_proj.bias', 'transformer.gpt2.h.3.mlp.c_proj.bias', 'transformer.gpt2.h.16.mlp.c_fc.weight', 'transformer.gpt2.h.16.mlp.c_proj.weight', 'transformer.gpt2.h.11.ln_2.weight', 'transformer.gpt2.h.22.mlp.c_fc.weight', 'transformer.gpt2.h.5.ln_2.bias', 'transformer.gpt2.h.6.ln_1.weight', 'transformer.gpt2.h.19.ln_1.bias', 'transformer.gpt2.h.0.mlp.c_fc.bias', 'transformer.gpt2.h.4.mlp.c_proj.weight', 'transformer.gpt2.h.4.attn.c_proj.weight', 'transformer.gpt2.h.3.ln_1.bias', 'transformer.gpt2.h.11.mlp.c_fc.bias', 'transformer.gpt2.h.15.attn.c_proj.bias', 'transformer.gpt2.h.15.mlp.c_proj.weight', 'transformer.gpt2.h.16.attn.c_attn.bias', 'transformer.gpt2.h.16.mlp.c_fc.bias', 'transformer.gpt2.h.17.attn.c_proj.bias', 'transformer.gpt2.h.14.attn.c_attn.bias', 'transformer.gpt2.h.9.attn.c_attn.weight', 'transformer.gpt2.h.19.mlp.c_proj.weight', 'transformer.gpt2.h.6.attn.c_proj.bias', 'transformer.gpt2.h.3.ln_2.weight', 'transformer.gpt2.h.16.ln_2.bias', 'transformer.gpt2.h.11.attn.c_attn.weight', 'transformer.gpt2.h.2.mlp.c_proj.weight', 'transformer.gpt2.h.6.ln_2.bias', 'transformer.gpt2.h.18.mlp.c_proj.bias', 'transformer.gpt2.h.21.ln_1.bias', 'transformer.gpt2.h.22.attn.c_attn.weight', 'transformer.gpt2.h.23.attn.c_proj.bias', 'transformer.gpt2.h.10.attn.c_proj.bias', 'transformer.gpt2.h.5.mlp.c_fc.weight', 'transformer.gpt2.h.15.attn.c_attn.bias', 'transformer.gpt2.h.15.attn.c_proj.weight', 'transformer.gpt2.h.8.attn.c_proj.weight', 'transformer.gpt2.h.15.mlp.c_fc.bias', 'transformer.gpt2.h.22.ln_2.weight', 'transformer.gpt2.h.1.attn.c_proj.bias', 'transformer.gpt2.h.19.attn.c_proj.weight', 'transformer.gpt2.h.1.ln_1.bias', 'transformer.gpt2.h.11.ln_1.weight', 'transformer.gpt2.h.3.mlp.c_proj.weight', 'transformer.gpt2.h.5.attn.c_attn.bias', 'transformer.gpt2.h.23.mlp.c_fc.weight', 'transformer.gpt2.h.23.ln_1.weight', 'transformer.gpt2.h.5.ln_1.weight', 'transformer.gpt2.h.19.ln_1.weight', 'transformer.gpt2.h.0.mlp.c_proj.weight', 'transformer.gpt2.h.20.mlp.c_proj.weight', 'transformer.gpt2.h.2.attn.c_attn.weight', 'transformer.gpt2.h.10.attn.c_attn.weight', 'transformer.gpt2.h.10.ln_1.weight', 'transformer.gpt2.h.19.mlp.c_proj.bias', 'transformer.gpt2.h.20.mlp.c_fc.bias', 'transformer.gpt2.h.3.attn.c_attn.weight', 'transformer.gpt2.h.4.mlp.c_proj.bias', 'transformer.gpt2.h.13.ln_2.bias', 'transformer.gpt2.h.14.ln_2.weight', 'transformer.gpt2.h.17.mlp.c_fc.bias', 'transformer.gpt2.h.18.ln_1.weight', 'transformer.gpt2.h.9.attn.c_proj.bias', 'transformer.gpt2.h.12.ln_1.bias', 'transformer.gpt2.h.1.mlp.c_fc.weight', 'transformer.gpt2.h.19.attn.c_attn.bias', 'transformer.gpt2.h.20.mlp.c_proj.bias', 'transformer.gpt2.h.12.mlp.c_proj.bias', 'transformer.gpt2.h.15.mlp.c_proj.bias', 'transformer.gpt2.h.19.mlp.c_fc.bias', 'transformer.gpt2.h.10.attn.c_proj.weight', 'transformer.gpt2.h.14.mlp.c_proj.bias', 'transformer.gpt2.h.21.attn.c_proj.bias', 'transformer.gpt2.h.5.attn.c_proj.weight', 'transformer.gpt2.h.16.attn.c_proj.weight', 'transformer.gpt2.h.20.mlp.c_fc.weight', 'transformer.gpt2.h.22.attn.c_proj.weight', 'transformer.gpt2.h.1.attn.c_attn.bias', 'transformer.gpt2.ln_f.bias', 'transformer.gpt2.h.8.mlp.c_proj.weight', 'transformer.gpt2.h.21.mlp.c_fc.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/spanish/04-twisted_remover_with_emoticons/feature_extractions/gpt2/DeepESP_gpt2-spanish-medium.pkl\n"
     ]
    }
   ],
   "source": [
    "#language =  'italian'\n",
    "language =  'spanish'\n",
    "#language =  'greek'\n",
    "\n",
    "cleanings = ['00-dirty_dataset','01-basic_remover','02-basic_remover_without_stopwords','03-basic_remover_without_stopwords_with_stemming','04-twisted_remover_with_emoticons']\n",
    "\n",
    "#case = 'bert'\n",
    "#case = 'roberta'\n",
    "case = 'gpt2'\n",
    "\n",
    "#reps_models = [\"dccuchile/bert-base-spanish-wwm-uncased\",\"dccuchile/bert-base-spanish-wwm-cased\",\"Geotrend/bert-base-es-cased\",\"dccuchile/tulio-chilean-spanish-bert\",\"dccuchile/patana-chilean-spanish-bert\"]\n",
    "#reps_models = [\"MMG/mlm-spanish-roberta-base\",\"llange/xlm-roberta-large-spanish\"]\n",
    "reps_models = [\"DeepESP/gpt2-spanish\",\"datificate/gpt2-small-spanish\",\"mrm8488/spanish-gpt2\",\"DeepESP/gpt2-spanish-medium\"]\n",
    "\n",
    "for combo in itertools.product(cleanings,reps_models):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    with open('data/'+ language +'/'+ combo[0] +'/data.pkl','rb') as file:\n",
    "        WF = pickle.load(file)\n",
    "    \n",
    "    pretrained_model = RepresentationModel(model_type=case,model_name=combo[1],use_cuda=False) \n",
    "    sentence_vectors = pretrained_model.encode_sentences(WF['text'], combine_strategy=\"mean\")\n",
    "    sentence_vectors = np.split(sentence_vectors,sentence_vectors.shape[0])\n",
    "    pandasseries = pd.Series(sentence_vectors)\n",
    "    WF['reps'] = pandasseries.copy()\n",
    "    data = pd.DataFrame()\n",
    "    data['reps'] = WF['reps'].copy()\n",
    "    data['relevance'] = WF['relevance'].copy()\n",
    "\n",
    "    link = 'data/'+ language +'/'+ combo[0] +'/feature_extractions/'+case+'/'+ str(combo[1]).replace('/', '_')+'.pkl'\n",
    "    \n",
    "    print(link)\n",
    "    \n",
    "    with open(link , 'wb') as file:\n",
    "        pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a81fa9fd-91b1-48f0-9a3a-82a93bc1d718",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForTextRepresentation were not initialized from the model checkpoint at ClassCat/gpt2-small-greek-v2 and are newly initialized: ['transformer.gpt2.h.3.mlp.c_fc.bias', 'transformer.gpt2.wpe.weight', 'transformer.gpt2.h.0.attn.c_attn.weight', 'transformer.gpt2.wte.weight', 'transformer.gpt2.h.7.mlp.c_proj.weight', 'transformer.gpt2.h.2.ln_2.bias', 'transformer.gpt2.h.2.attn.c_proj.weight', 'transformer.gpt2.h.6.attn.c_proj.weight', 'transformer.gpt2.h.7.mlp.c_fc.weight', 'transformer.gpt2.h.5.attn.c_proj.bias', 'transformer.gpt2.h.0.attn.c_proj.bias', 'transformer.gpt2.h.7.ln_1.bias', 'transformer.gpt2.h.7.ln_2.bias', 'transformer.gpt2.h.2.ln_1.bias', 'transformer.gpt2.h.0.mlp.c_proj.bias', 'transformer.gpt2.h.0.ln_1.bias', 'transformer.gpt2.h.4.ln_1.weight', 'transformer.gpt2.h.0.ln_1.weight', 'transformer.gpt2.h.1.attn.c_attn.weight', 'transformer.gpt2.h.6.mlp.c_proj.weight', 'transformer.gpt2.h.2.attn.c_proj.bias', 'transformer.gpt2.h.3.attn.c_proj.weight', 'transformer.gpt2.h.2.attn.c_attn.bias', 'transformer.gpt2.h.5.ln_1.bias', 'transformer.gpt2.h.5.mlp.c_fc.bias', 'transformer.gpt2.h.0.ln_2.weight', 'transformer.gpt2.h.7.attn.c_attn.bias', 'transformer.gpt2.h.6.mlp.c_fc.weight', 'transformer.gpt2.h.6.ln_2.weight', 'transformer.gpt2.h.3.attn.c_attn.bias', 'transformer.gpt2.h.2.ln_2.weight', 'transformer.gpt2.h.3.mlp.c_fc.weight', 'transformer.gpt2.h.7.mlp.c_fc.bias', 'transformer.gpt2.h.3.attn.c_proj.bias', 'transformer.gpt2.h.6.ln_1.bias', 'transformer.gpt2.h.1.ln_1.weight', 'transformer.gpt2.h.7.attn.c_proj.weight', 'transformer.gpt2.h.5.mlp.c_proj.weight', 'transformer.gpt2.h.5.ln_2.weight', 'transformer.gpt2.h.4.attn.c_attn.weight', 'transformer.gpt2.h.7.attn.c_proj.bias', 'transformer.gpt2.h.6.mlp.c_fc.bias', 'transformer.gpt2.h.6.attn.c_attn.bias', 'transformer.gpt2.h.3.ln_2.bias', 'transformer.gpt2.h.4.mlp.c_fc.bias', 'transformer.gpt2.ln_f.weight', 'transformer.gpt2.h.1.ln_2.bias', 'transformer.gpt2.h.7.attn.c_attn.weight', 'transformer.gpt2.h.4.attn.c_proj.bias', 'transformer.gpt2.h.4.mlp.c_fc.weight', 'transformer.gpt2.h.7.ln_2.weight', 'transformer.gpt2.h.5.attn.c_attn.weight', 'transformer.gpt2.h.5.mlp.c_proj.bias', 'transformer.gpt2.h.0.mlp.c_fc.weight', 'transformer.gpt2.h.7.mlp.c_proj.bias', 'transformer.gpt2.h.7.ln_1.weight', 'transformer.gpt2.h.4.ln_2.bias', 'transformer.gpt2.h.1.attn.c_proj.weight', 'transformer.gpt2.h.3.ln_1.weight', 'transformer.gpt2.h.1.ln_2.weight', 'transformer.gpt2.h.0.ln_2.bias', 'transformer.gpt2.h.4.ln_1.bias', 'transformer.gpt2.h.2.mlp.c_fc.weight', 'transformer.gpt2.h.6.mlp.c_proj.bias', 'transformer.gpt2.h.1.mlp.c_proj.weight', 'transformer.gpt2.h.4.ln_2.weight', 'transformer.gpt2.h.1.mlp.c_fc.bias', 'transformer.gpt2.h.6.attn.c_attn.weight', 'transformer.gpt2.h.4.attn.c_attn.bias', 'transformer.gpt2.h.2.mlp.c_proj.bias', 'transformer.gpt2.h.2.mlp.c_fc.bias', 'transformer.gpt2.h.2.ln_1.weight', 'transformer.gpt2.h.0.attn.c_proj.weight', 'transformer.gpt2.h.0.attn.c_attn.bias', 'transformer.gpt2.h.1.mlp.c_proj.bias', 'transformer.gpt2.h.3.mlp.c_proj.bias', 'transformer.gpt2.h.5.ln_2.bias', 'transformer.gpt2.h.6.ln_1.weight', 'transformer.gpt2.h.0.mlp.c_fc.bias', 'transformer.gpt2.h.4.mlp.c_proj.weight', 'transformer.gpt2.h.4.attn.c_proj.weight', 'transformer.gpt2.h.3.ln_1.bias', 'transformer.gpt2.h.6.attn.c_proj.bias', 'transformer.gpt2.h.3.ln_2.weight', 'transformer.gpt2.h.2.mlp.c_proj.weight', 'transformer.gpt2.h.6.ln_2.bias', 'transformer.gpt2.h.5.mlp.c_fc.weight', 'transformer.gpt2.h.1.attn.c_proj.bias', 'transformer.gpt2.h.1.ln_1.bias', 'transformer.gpt2.h.3.mlp.c_proj.weight', 'transformer.gpt2.h.5.attn.c_attn.bias', 'transformer.gpt2.h.5.ln_1.weight', 'transformer.gpt2.h.0.mlp.c_proj.weight', 'transformer.gpt2.h.2.attn.c_attn.weight', 'transformer.gpt2.h.3.attn.c_attn.weight', 'transformer.gpt2.h.4.mlp.c_proj.bias', 'transformer.gpt2.h.1.mlp.c_fc.weight', 'transformer.gpt2.h.5.attn.c_proj.weight', 'transformer.gpt2.h.1.attn.c_attn.bias', 'transformer.gpt2.ln_f.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/greek/04-twisted_remover_with_emoticons/feature_extractions/gpt2/ClassCat_gpt2-small-greek-v2.pkl\n"
     ]
    }
   ],
   "source": [
    "#language =  'italian'\n",
    "#language =  'spanish'\n",
    "language =  'greek'\n",
    "\n",
    "cleanings = ['00-dirty_dataset','01-basic_remover','02-basic_remover_without_stopwords','03-basic_remover_without_stopwords_with_stemming','04-twisted_remover_with_emoticons']\n",
    "\n",
    "#model_type = 'bert'\n",
    "#case = 'roberta'\n",
    "model_type = 'gpt2'\n",
    "\n",
    "#reps_models = [\"Geotrend/bert-base-el-cased\",\"nlpaueb/bert-base-greek-uncased-v1\",\"dimitriz/st-greek-media-bert-base-uncased\",\"petros/bert-base-cypriot-uncased-v1\"]\n",
    "reps_models = [\"lighteternal/gpt2-finetuned-greek-small\",\"lighteternal/gpt2-finetuned-greek\",\"nikokons/gpt2-greek\",\"ClassCat/gpt2-small-greek-v2\"]\n",
    "\n",
    "for combo in itertools.product(cleanings,reps_models):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    with open('data/'+ language +'/'+ combo[0] +'/data.pkl','rb') as file:\n",
    "        WF = pickle.load(file)\n",
    "    \n",
    "    pretrained_model = RepresentationModel(model_type=model_type,model_name=combo[1],use_cuda=False) \n",
    "    sentence_vectors = pretrained_model.encode_sentences(WF['text'], combine_strategy=\"mean\")\n",
    "    sentence_vectors = np.split(sentence_vectors,sentence_vectors.shape[0])\n",
    "    pandasseries = pd.Series(sentence_vectors)\n",
    "    WF['reps'] = pandasseries.copy()\n",
    "    data = pd.DataFrame()\n",
    "    data['reps'] = WF['reps'].copy()\n",
    "    data['relevance'] = WF['relevance'].copy()\n",
    "    \n",
    "    link = 'data/'+ language +'/'+ combo[0] +'/feature_extractions/'+model_type+'/'+ str(combo[1]).replace('/', '_')+'.pkl'\n",
    "    \n",
    "    print(link)\n",
    "    \n",
    "    with open(link , 'wb') as file:\n",
    "        pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066ce0ce-fa25-4bb8-baec-c76a44a0d622",
   "metadata": {},
   "source": [
    "## POST PROCESSING HYPER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4de36109-af3a-4157-8773-a8f6ea096244",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/italian/00-dirty_dataset/feature_extractions/bert/dbmdz_bert-base-italian-cased.pkl\n",
      "data/italian/00-dirty_dataset/feature_extractions/bert/dbmdz_bert-base-italian-uncased.pkl\n",
      "data/italian/00-dirty_dataset/feature_extractions/bert/dbmdz_bert-base-italian-xxl-cased.pkl\n",
      "data/italian/00-dirty_dataset/feature_extractions/bert/dbmdz_bert-base-italian-xxl-uncased.pkl\n",
      "data/italian/01-basic_remover/feature_extractions/bert/dbmdz_bert-base-italian-cased.pkl\n",
      "data/italian/01-basic_remover/feature_extractions/bert/dbmdz_bert-base-italian-uncased.pkl\n",
      "data/italian/01-basic_remover/feature_extractions/bert/dbmdz_bert-base-italian-xxl-cased.pkl\n",
      "data/italian/01-basic_remover/feature_extractions/bert/dbmdz_bert-base-italian-xxl-uncased.pkl\n",
      "data/italian/02-basic_remover_without_stopwords/feature_extractions/bert/dbmdz_bert-base-italian-cased.pkl\n",
      "data/italian/02-basic_remover_without_stopwords/feature_extractions/bert/dbmdz_bert-base-italian-uncased.pkl\n",
      "data/italian/02-basic_remover_without_stopwords/feature_extractions/bert/dbmdz_bert-base-italian-xxl-cased.pkl\n",
      "data/italian/02-basic_remover_without_stopwords/feature_extractions/bert/dbmdz_bert-base-italian-xxl-uncased.pkl\n",
      "data/italian/03-basic_remover_without_stopwords_with_stemming/feature_extractions/bert/dbmdz_bert-base-italian-cased.pkl\n",
      "data/italian/03-basic_remover_without_stopwords_with_stemming/feature_extractions/bert/dbmdz_bert-base-italian-uncased.pkl\n",
      "data/italian/03-basic_remover_without_stopwords_with_stemming/feature_extractions/bert/dbmdz_bert-base-italian-xxl-cased.pkl\n",
      "data/italian/03-basic_remover_without_stopwords_with_stemming/feature_extractions/bert/dbmdz_bert-base-italian-xxl-uncased.pkl\n",
      "data/italian/04-twisted_remover_with_emoticons/feature_extractions/bert/dbmdz_bert-base-italian-cased.pkl\n",
      "data/italian/04-twisted_remover_with_emoticons/feature_extractions/bert/dbmdz_bert-base-italian-uncased.pkl\n",
      "data/italian/04-twisted_remover_with_emoticons/feature_extractions/bert/dbmdz_bert-base-italian-xxl-cased.pkl\n",
      "data/italian/04-twisted_remover_with_emoticons/feature_extractions/bert/dbmdz_bert-base-italian-xxl-uncased.pkl\n"
     ]
    }
   ],
   "source": [
    "# I just change the combinations of language and model_type\n",
    "\n",
    "language =  'italian'\n",
    "#language =  'spanish'\n",
    "#language =  'greek'\n",
    "\n",
    "cleanings = ['00-dirty_dataset','01-basic_remover','02-basic_remover_without_stopwords','03-basic_remover_without_stopwords_with_stemming','04-twisted_remover_with_emoticons']\n",
    "\n",
    "model_type = 'bert'\n",
    "# ase = 'roberta' didn't manage to get representations yet\n",
    "#case = 'gpt-2' probably the code needs reformation\n",
    "\n",
    "for cleaning in cleanings:\n",
    "    path = 'data/'+ language +'/'+ cleaning + '/feature_extractions/' + model_type\n",
    "    for x in os.listdir(path):\n",
    "        file = path + '/' + x\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29f16d98-1d39-4ce1-bdcf-ab1dbb1060b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reps</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.16349472, -0.022513028, 0.1601058, 0.3005...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.1870734, -0.1289106, 0.36564282, 0.020390...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.058511183, -0.09192906, -0.24975105, 0.45...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.07063484, -0.08345323, 0.18612616, 0.2530...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.09547403, 0.21283852, 0.012412298, 0.3508...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>[[-0.030228468, -0.14970928, 0.20723383, 0.424...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>[[-0.115419574, 0.18743767, 0.23865303, 0.2736...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>[[-0.042768005, 0.074689046, 0.05405128, 0.196...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>[[-0.09403053, -0.04718489, 0.18331964, 0.4239...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>[[0.055064242, -0.059358418, 0.063184425, 0.28...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1892 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   reps  relevance\n",
       "0     [[-0.16349472, -0.022513028, 0.1601058, 0.3005...          1\n",
       "1     [[-0.1870734, -0.1289106, 0.36564282, 0.020390...          0\n",
       "2     [[-0.058511183, -0.09192906, -0.24975105, 0.45...          1\n",
       "3     [[-0.07063484, -0.08345323, 0.18612616, 0.2530...          1\n",
       "4     [[-0.09547403, 0.21283852, 0.012412298, 0.3508...          1\n",
       "...                                                 ...        ...\n",
       "1887  [[-0.030228468, -0.14970928, 0.20723383, 0.424...          0\n",
       "1888  [[-0.115419574, 0.18743767, 0.23865303, 0.2736...          1\n",
       "1889  [[-0.042768005, 0.074689046, 0.05405128, 0.196...          1\n",
       "1890  [[-0.09403053, -0.04718489, 0.18331964, 0.4239...          0\n",
       "1891  [[0.055064242, -0.059358418, 0.063184425, 0.28...          1\n",
       "\n",
       "[1892 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'data/italian/00-dirty_dataset/feature_extractions/bert/dbmdz_bert-base-italian-cased.pkl'\n",
    "\n",
    "with open(file, \"rb\") as file:\n",
    "    WF = pickle.load(file)\n",
    "WF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "000f719d-ad77-4b91-8f9a-b03d599d06b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_names</th>\n",
       "      <th>data_types</th>\n",
       "      <th>shape_len</th>\n",
       "      <th>unique_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reps</td>\n",
       "      <td>&lt;class 'numpy.ndarray'&gt;</td>\n",
       "      <td>(1, 768)</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relevance</td>\n",
       "      <td>&lt;class 'numpy.int64'&gt;</td>\n",
       "      <td>()</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  column_names               data_types shape_len  unique_values\n",
       "0         reps  <class 'numpy.ndarray'>  (1, 768)           1892\n",
       "1    relevance    <class 'numpy.int64'>        ()              2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_tweet_report(WF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ccdb1cc-c535-4980-a869-ec7e8d8bf8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>count</th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1258</td>\n",
       "      <td>66.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>634</td>\n",
       "      <td>33.51%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevance  count balance\n",
       "0          0   1258  66.49%\n",
       "1          1    634  33.51%"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_relevance_balance(WF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c55c0c41-bed1-4aaf-972d-a8b1018a01f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperspace = {\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'dropout_rate2': hp.uniform('dropout_rate2', 0.1, 0.5),\n",
    "    'dropout_rate3': hp.uniform('dropout_rate3', 0.1, 0.5),\n",
    "    'dropout_rate4': hp.uniform('dropout_rate4', 0.1, 0.5),\n",
    "    'dropout_rate5': hp.uniform('dropout_rate6', 0.1, 0.5),\n",
    "    'relovir': hp.uniform('relovir', 0.1, 0.5),\n",
    "    'PostEmbedding#nods': hp.quniform('PostEmbedding#nods', 1 , 768, q=1),\n",
    "    'batch_size' : hp.quniform('batch_size',20,140,q=5),\n",
    "    'PostEmbedding#nods2': hp.quniform('PostEmbedding#nods2', 1 , 768, q=1),\n",
    "    'PostEmbedding#nods3': hp.quniform('PostEmbedding#nods3', 1 , 768, q=1),\n",
    "    'PostEmbedding#nods4': hp.quniform('PostEmbedding#nods4', 1 , 768, q=1),\n",
    "    'PostEmbedding#nods5': hp.quniform('PostEmbedding#nods5', 1 , 768, q=1),\n",
    "    'PrePredictionActivation':hp.choice('PrePredictionActivation',['softmax','sigmoid'])\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "483fde87-7bb8-4e82-8e9d-7908101bcec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Το training set X: <class 'numpy.ndarray'> με (1222, 768)\n",
      "To test set X: <class 'numpy.ndarray'> με (568, 768)\n",
      "To training set y: <class 'numpy.ndarray'> με (1222,)\n",
      "To test set y: <class 'numpy.ndarray'> με (568,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "        \n",
    "def datasplit_new(df,testsize,relovir):\n",
    "    \"\"\"\n",
    "    Firstly we split the dataset into train and test parts.\n",
    "    \n",
    "    Then we create the training dataset by picking up the irrelevant tweets from the training \n",
    "    split part with only the number of relevant tweet\n",
    "    \n",
    "    The relovir variable represents the relative ratio of irrelevant(we usually have more irrelevant so) \n",
    "    over relevant number of training examples in the set.\n",
    "    \n",
    "    Returns as a (examples,768) np array the representations and the y as (examples,) shaped np array.\n",
    "    \n",
    "    Future: we need to be able to reduce zero and one examples accordinglydepending of which \n",
    "    \n",
    "    \"\"\"\n",
    "    # make a copied instance of the dataset\n",
    "    df = df.copy()\n",
    "    # we split the dataset into train and test subsets\n",
    "    df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(df['reps'], df['relevance'], test_size = testsize)\n",
    "    # reconstruct training set\n",
    "    if relovir>0:\n",
    "        training_set = pd.DataFrame()\n",
    "        training_set['reps'] = df_X_train.copy()\n",
    "        training_set['relevance'] = df_y_train.copy()\n",
    "        training_set.reset_index(drop = True)\n",
    "        # we split the training dataset by relervance into two DataFrames irr and rel\n",
    "        grouping = training_set.groupby('relevance')\n",
    "        group_dict = {}\n",
    "        for name, group in grouping:\n",
    "            group_dict[str(name)] = group\n",
    "        # we find the absolute numbers \n",
    "        df_training_irr = group_dict['0'].reset_index(drop = True)\n",
    "        df_training_rel = group_dict['1'].reset_index(drop = True)\n",
    "        # based on the relovir parameter pick up the set with the appropriate ratio, here an explanation for the inner if is needed:\n",
    "        Nrel = len(df_training_rel)\n",
    "        # print(Nrel)\n",
    "        Nirr = len(df_training_irr)\n",
    "        # print(Nirr)\n",
    "        N = Nrel + Nirr\n",
    "        if relovir<=1:\n",
    "            if relovir<Nrel/Nirr:\n",
    "                relevant_part = df_training_rel.sample(n = int(Nirr*relovir))\n",
    "                df_training = pd.concat([df_training_irr, relevant_part]).sample(frac=1).reset_index(drop = True)\n",
    "            else:\n",
    "                df_training = pd.concat([df_training_irr, df_training_rel]).sample(frac=1).reset_index(drop = True)\n",
    "        else:\n",
    "            if relovir<Nrel/Nirr:\n",
    "                irrelevant_part = df_training_irr.sample(n = int((1/relovir)*Nrel))\n",
    "                df_training = pd.concat([df_training_rel, irrelevant_part]).sample(frac=1).reset_index(drop = True)\n",
    "            else:\n",
    "                df_training = pd.concat([df_training_irr, df_training_rel]).sample(frac=1).reset_index(drop = True)\n",
    "        df_X_train = df_training['reps'].copy()\n",
    "        df_y_train = df_training['relevance'].copy()\n",
    "    else:\n",
    "        print(\"relovir can't be negative or zero\")\n",
    "    df_X_train.apply(lambda x: x.reshape(768,))\n",
    "    df_X_test = df_X_test.copy().apply(lambda x: x.reshape(768,))\n",
    "    training_set_X = np.vstack(df_X_train)\n",
    "    test_set_X = np.vstack(df_X_test)\n",
    "    y_train = np.vstack(df_y_train).reshape(-1)\n",
    "    y_test = np.vstack(df_y_test).reshape(-1)\n",
    "    return training_set_X, test_set_X, y_train, y_test\n",
    "\n",
    "training_set_X, test_set_X, training_set_y, test_set_y = datasplit_new(WF,0.3,relovir = 0.4)\n",
    "print(f\"Το training set X: {type(training_set_X)} με {training_set_X.shape}\")\n",
    "print(f\"To test set X: {type(test_set_X)} με {test_set_X.shape}\")\n",
    "print(f\"To training set y: {type(training_set_y)} με {training_set_y.shape}\")\n",
    "print(f\"To test set y: {type(test_set_y )} με {test_set_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad61bba9-7874-418e-9a76-70636f0612fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def modelize(calibrers):  \n",
    "    \n",
    "    hyperparameters = {\n",
    "                   'ITERATIONS':'15',\n",
    "                   'EPOCHS': '50',\n",
    "                   'LOSS':\"'binary_crossentropy'\",\n",
    "                   'OPTIMIZER': 'Adam(learning_rate=0.0001)',\n",
    "                   'METRICS': \"\"\"['acc', metrics.precision, metrics.recall, metrics.f1]\"\"\",\n",
    "                   'BATCH_SIZE': \"\"\"calibrers['batch_size']\"\"\",\n",
    "                   'TEST_SIZE': '0.3',\n",
    "                   'RELOVIR': \"\"\"calibrers['relovir']\"\"\"}\n",
    "    \n",
    "    for key, value in hyperparameters.items():\n",
    "        globals()[key] = eval(value)\n",
    "    \n",
    "    av_loss_train = np.zeros(EPOCHS)\n",
    "    av_loss_val = np.zeros(EPOCHS)\n",
    "    av_acc_train = np.zeros(EPOCHS)\n",
    "    av_acc_val = np.zeros(EPOCHS)\n",
    "    av_prec_train = np.zeros(EPOCHS)\n",
    "    av_prec_val = np.zeros(EPOCHS)\n",
    "    av_rec_train = np.zeros(EPOCHS)\n",
    "    av_rec_val = np.zeros(EPOCHS)\n",
    "    av_f1_train = np.zeros(EPOCHS)\n",
    "    av_f1_val = np.zeros(EPOCHS)\n",
    "    \n",
    "    iter_time = 0\n",
    "    \n",
    "    for iteration in range(ITERATIONS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        training_set_X, test_set_X, training_set_y, test_set_y = datasplit_new(WF,0.3,relovir = RELOVIR)\n",
    "        \n",
    "        model = None\n",
    "    \n",
    "        #np.random.seed(SEED)\n",
    "    \n",
    "        #initializer choice\n",
    "    \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Input(shape = (768,)))\n",
    "        \n",
    "        model.add(Dense(calibrers['PostEmbedding#nods'],activation='relu'))\n",
    "        model.add(Dropout(calibrers['dropout_rate']))\n",
    "        \n",
    "        model.add(Dense(calibrers['PostEmbedding#nods2'],activation='relu'))\n",
    "        model.add(Dropout(calibrers['dropout_rate2']))\n",
    "        \n",
    "        model.add(Dense(calibrers['PostEmbedding#nods3'],activation='relu'))\n",
    "        model.add(Dropout(calibrers['dropout_rate3']))\n",
    "        \n",
    "        model.add(Dense(calibrers['PostEmbedding#nods4'],activation='relu'))\n",
    "        model.add(Dropout(calibrers['dropout_rate4']))\n",
    "        \n",
    "        model.add(Dense(calibrers['PostEmbedding#nods5'],activation='relu'))\n",
    "        model.add(Dropout(calibrers['dropout_rate5']))     \n",
    "        \n",
    "        model.add(Dense(1,activation = calibrers['PrePredictionActivation']))\n",
    "        \n",
    "        model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)\n",
    "    \n",
    "        #print(type(model.summary()))\n",
    "              \n",
    "        clear_output(wait=True)\n",
    "        print(f'iteration {iteration-1} took {iter_time} s or {iter_time/60} min')\n",
    "    \n",
    "        history = model.fit(training_set_X, training_set_y,validation_data=( test_set_X,  test_set_y), batch_size = int(BATCH_SIZE), epochs = EPOCHS, verbose = 0,callbacks=[],shuffle = True)\n",
    "    \n",
    "    \n",
    "        #training metrics\n",
    "        av_loss_train = np.add(av_loss_train,np.array(history.history['loss']))\n",
    "        av_acc_train = np.add(av_acc_train,np.array(history.history['acc']))\n",
    "        av_prec_train = np.add(av_prec_train,np.array(history.history['precision']))\n",
    "        av_rec_train = np.add(av_rec_train,np.array(history.history['recall']))\n",
    "        av_f1_train = np.add(av_f1_train,np.array(history.history['f1']))\n",
    "        #validation metrics\n",
    "        av_loss_val = np.add(av_loss_val,np.array(history.history['val_loss']))\n",
    "        av_acc_val = np.add(av_acc_val,np.array(history.history['val_acc']))\n",
    "        av_prec_val = np.add(av_prec_val,np.array(history.history['val_precision']))\n",
    "        av_rec_val = np.add(av_rec_val,np.array(history.history['val_recall']))\n",
    "        av_f1_val = np.add(av_f1_val,np.array(history.history['val_f1']))\n",
    "    \n",
    "        end_time = time.time()\n",
    "    \n",
    "        iter_time = end_time-start_time\n",
    "    \n",
    "    av_loss_train = np.divide(av_loss_train,ITERATIONS)\n",
    "    av_acc_train = np.divide(av_acc_train,ITERATIONS)\n",
    "    av_prec_train = np.divide(av_prec_train,ITERATIONS)\n",
    "    av_rec_train = np.divide(av_rec_train,ITERATIONS)\n",
    "    av_f1_train = np.divide(av_f1_train,ITERATIONS)\n",
    "\n",
    "    av_loss_val = np.divide(av_loss_val,ITERATIONS)\n",
    "    av_acc_val = np.divide(av_acc_val,ITERATIONS)\n",
    "    av_prec_val = np.divide(av_prec_val,ITERATIONS)\n",
    "    av_rec_val = np.divide(av_rec_val,ITERATIONS)\n",
    "    av_f1_val = np.divide(av_f1_val,ITERATIONS)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "\n",
    "    results = pd.DataFrame({'train_loss': av_loss_train,'train_acc': av_acc_train,'train_prec': av_prec_train,'train_rec': av_rec_train,'train_f1': av_f1_train,'val_loss': av_loss_val,'val_acc': av_acc_val,'val_prec': av_prec_val,'val_rec': av_rec_val,'val_f1': av_f1_val})\n",
    "    \n",
    "    path = \"runs\"\n",
    "    dirs = os.listdir(path)\n",
    "    dirs.sort(reverse = True)\n",
    "    the_run = dirs[0]\n",
    "    match = re.search(r\"run\\d{5}\", the_run)[0][3:]\n",
    "    match = f'{(int(match)+1):05}'\n",
    "    the_folder = f\"run{match}\"\n",
    "    directory = os.path.join(path, the_folder)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory {the_folder} created!\")\n",
    "    else:\n",
    "        print(\"Directory already exists.\")\n",
    "    \n",
    "    #####################\n",
    "    # now save the results pickle and the hyperparameter text in the correct run folder\n",
    "    filepath = f\"runs\" +f\"/{the_folder}\"\n",
    "    sub_dir1 = os.path.join(filepath,'results.plk')\n",
    "    sub_dir2 = os.path.join(filepath,\"hyperparameters.txt\")\n",
    "    with open(sub_dir1, 'wb') as dummy:\n",
    "        pickle.dump(results, dummy)\n",
    "        \n",
    "    hyperparameters = {\n",
    "                   'ITERATIONS':'5',\n",
    "                   'EPOCHS': '50',\n",
    "                   'LOSS':\"'binary_crossentropy'\",\n",
    "                   'OPTIMIZER': 'Adam(learning_rate=0.0001)',\n",
    "                   'METRICS': \"\"\"['acc', metrics.precision, metrics.recall, metrics.f1]\"\"\",\n",
    "                   'BATCH_SIZE': BATCH_SIZE,\n",
    "                   'TEST_SIZE': '0.3',\n",
    "                   'RELOVIR': RELOVIR }\n",
    "    \n",
    "    \n",
    "    with open(sub_dir2, 'w') as file:\n",
    "        for key in hyperparameters:\n",
    "            file.write('\\n '+ key + ':' + str(hyperparameters[key]) + '\\n')\n",
    "            \n",
    "    # txt with the n maximum val_f1 epochs and their values\n",
    "    n=10\n",
    "    if EPOCHS<n:\n",
    "        n = 1\n",
    "    sub_dir3 = os.path.join(filepath,\"val_f1.txt\")\n",
    "    x = list(results['val_f1'].nlargest(n).index)\n",
    "    print(x)\n",
    "    nums = list(map(lambda x: round(results['val_f1'].loc[x],4),x))\n",
    "    print(nums)\n",
    "    text = 'epoch value\\n'\n",
    "    for i in range(n):\n",
    "        text+=f'-{(x[i]):03}- {nums[i]}\\n'\n",
    "    with open(sub_dir3, 'wb') as dummy:\n",
    "        dummy.write(text.encode())\n",
    "        \n",
    "    #####################\n",
    "    # now save the plot pictures(not particularly usefull in the general code)\n",
    "    plt.plot(results['val_acc'])\n",
    "    plt.plot(results['val_prec'])\n",
    "    plt.plot(results['val_rec'])\n",
    "    plt.plot(results['val_f1'])\n",
    "    plt.title('Average Evaluation Model Metrics')\n",
    "    plt.ylabel('Value')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['accuracy','precision','recall','f1-score'], loc='lower right')#, bbox_to_anchor=(1, 0.5))\n",
    "    plt.savefig(f'runs/{the_folder}/AEMM.jpg',dpi = 300)\n",
    "    plt.show()\n",
    "    \n",
    "    ######################\n",
    "    # save model summary\n",
    "    with open(f'runs/{the_folder}/model_summary.txt', 'w') as f:\n",
    "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "    print(results)\n",
    "    \n",
    "    av_f1_val = np.add(av_f1_val,np.array(history.history['val_f1']))\n",
    " \n",
    "    return -np.max(np.divide(av_f1_val,ITERATIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d3293d5-91c5-419c-ae53-b46f5f12bd6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory run00009 created!                                                       \n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]                                                    \n",
      "[0.4997, 0.4997, 0.4997, 0.4997, 0.4997, 0.4997, 0.4997, 0.4997, 0.4997, 0.4997]  \n",
      " 80%|████████  | 4/5 [09:52<02:04, 124.55s/trial, best loss: -0.11442983706792195]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train_loss  train_acc  train_prec  train_rec  train_f1  val_loss  \\           \n",
      "0     0.618957   0.331344    0.330348   1.000000  0.494702  0.489211   \n",
      "1     0.450723   0.331344    0.329399   0.989744  0.492411  0.349541   \n",
      "2     0.354615   0.331344    0.329331   0.994872  0.493583  0.308190   \n",
      "3     0.306957   0.331344    0.327255   0.984615  0.489409  0.286445   \n",
      "4     0.273086   0.331344    0.329413   0.994872  0.493359  0.270294   \n",
      "5     0.249902   0.331344    0.332911   1.000000  0.497464  0.258026   \n",
      "6     0.223827   0.331344    0.334373   1.000000  0.499230  0.246968   \n",
      "7     0.210521   0.331344    0.332005   0.994872  0.495982  0.244046   \n",
      "8     0.192894   0.331344    0.330764   0.989744  0.493190  0.248776   \n",
      "9     0.181653   0.331344    0.328218   0.994872  0.491623  0.248259   \n",
      "10    0.168840   0.331344    0.326904   0.989744  0.489530  0.260659   \n",
      "11    0.162340   0.331344    0.331685   1.000000  0.496223  0.249550   \n",
      "12    0.156649   0.331344    0.324461   0.979487  0.485997  0.242927   \n",
      "13    0.143958   0.331344    0.330589   0.989744  0.493897  0.246821   \n",
      "14    0.135074   0.331344    0.331917   0.994872  0.495693  0.249284   \n",
      "15    0.124381   0.331344    0.329108   0.994872  0.492841  0.253491   \n",
      "16    0.116102   0.331344    0.329569   0.989744  0.492879  0.258110   \n",
      "17    0.110119   0.331344    0.334588   0.994872  0.497727  0.269712   \n",
      "18    0.101916   0.331344    0.330529   0.994872  0.494342  0.279006   \n",
      "19    0.094921   0.331344    0.332987   0.994872  0.496550  0.272399   \n",
      "20    0.089807   0.331344    0.331793   0.994872  0.495269  0.286350   \n",
      "21    0.084996   0.331344    0.330528   0.994872  0.494361  0.282551   \n",
      "22    0.075022   0.331344    0.331788   1.000000  0.496261  0.291753   \n",
      "23    0.068768   0.331344    0.330895   0.994872  0.494601  0.307166   \n",
      "24    0.068178   0.331344    0.333173   0.994872  0.496592  0.305015   \n",
      "25    0.059185   0.331344    0.326892   0.979487  0.487973  0.313350   \n",
      "26    0.054267   0.331344    0.331707   0.989744  0.494234  0.322871   \n",
      "27    0.051586   0.331344    0.329349   0.989744  0.492304  0.331524   \n",
      "28    0.048885   0.331344    0.329249   0.989744  0.492282  0.340341   \n",
      "29    0.043112   0.331344    0.325631   0.984615  0.488201  0.349880   \n",
      "30    0.041834   0.331344    0.329307   0.994872  0.493208  0.358893   \n",
      "31    0.037946   0.331344    0.326887   0.984615  0.488970  0.370467   \n",
      "32    0.035010   0.331344    0.328205   0.994872  0.491962  0.383804   \n",
      "33    0.036503   0.331344    0.327020   0.984615  0.489669  0.386239   \n",
      "34    0.033515   0.331344    0.332978   1.000000  0.497377  0.381397   \n",
      "35    0.030642   0.331344    0.328240   0.989744  0.491268  0.390802   \n",
      "36    0.030609   0.331344    0.328211   0.989744  0.491241  0.393220   \n",
      "37    0.025267   0.331344    0.330600   0.989744  0.493465  0.403690   \n",
      "38    0.023315   0.331344    0.333120   1.000000  0.497564  0.417747   \n",
      "39    0.021572   0.331344    0.332878   1.000000  0.497510  0.425085   \n",
      "40    0.023492   0.331344    0.333231   0.989744  0.495354  0.438062   \n",
      "41    0.020175   0.331344    0.330533   0.994872  0.494360  0.427507   \n",
      "42    0.017672   0.331344    0.330546   0.994872  0.494173  0.441485   \n",
      "43    0.018559   0.331344    0.338091   1.000000  0.502173  0.447728   \n",
      "44    0.014579   0.331344    0.328094   0.989744  0.490966  0.442998   \n",
      "45    0.014427   0.331344    0.335278   0.994872  0.498752  0.462926   \n",
      "46    0.011667   0.331344    0.326803   0.989744  0.489628  0.454352   \n",
      "47    0.010821   0.331344    0.329414   0.989744  0.492254  0.460205   \n",
      "48    0.010721   0.331344    0.335646   1.000000  0.499883  0.481539   \n",
      "49    0.010884   0.331344    0.328139   0.984615  0.490274  0.476054   \n",
      "\n",
      "     val_acc  val_prec  val_rec    val_f1  \n",
      "0   0.330986  0.335443      1.0  0.499749  \n",
      "1   0.330986  0.335443      1.0  0.499749  \n",
      "2   0.330986  0.335443      1.0  0.499749  \n",
      "3   0.330986  0.335443      1.0  0.499749  \n",
      "4   0.330986  0.335443      1.0  0.499749  \n",
      "5   0.330986  0.335443      1.0  0.499749  \n",
      "6   0.330986  0.335443      1.0  0.499749  \n",
      "7   0.330986  0.335443      1.0  0.499749  \n",
      "8   0.330986  0.335443      1.0  0.499749  \n",
      "9   0.330986  0.335443      1.0  0.499749  \n",
      "10  0.330986  0.335443      1.0  0.499749  \n",
      "11  0.330986  0.335443      1.0  0.499749  \n",
      "12  0.330986  0.335443      1.0  0.499749  \n",
      "13  0.330986  0.335443      1.0  0.499749  \n",
      "14  0.330986  0.335443      1.0  0.499749  \n",
      "15  0.330986  0.335443      1.0  0.499749  \n",
      "16  0.330986  0.335443      1.0  0.499749  \n",
      "17  0.330986  0.335443      1.0  0.499749  \n",
      "18  0.330986  0.335443      1.0  0.499749  \n",
      "19  0.330986  0.335443      1.0  0.499749  \n",
      "20  0.330986  0.335443      1.0  0.499749  \n",
      "21  0.330986  0.335443      1.0  0.499749  \n",
      "22  0.330986  0.335443      1.0  0.499749  \n",
      "23  0.330986  0.335443      1.0  0.499749  \n",
      "24  0.330986  0.335443      1.0  0.499749  \n",
      "25  0.330986  0.335443      1.0  0.499749  \n",
      "26  0.330986  0.335443      1.0  0.499749  \n",
      "27  0.330986  0.335443      1.0  0.499749  \n",
      "28  0.330986  0.335443      1.0  0.499749  \n",
      "29  0.330986  0.335443      1.0  0.499749  \n",
      "30  0.330986  0.335443      1.0  0.499749  \n",
      "31  0.330986  0.335443      1.0  0.499749  \n",
      "32  0.330986  0.335443      1.0  0.499749  \n",
      "33  0.330986  0.335443      1.0  0.499749  \n",
      "34  0.330986  0.335443      1.0  0.499749  \n",
      "35  0.330986  0.335443      1.0  0.499749  \n",
      "36  0.330986  0.335443      1.0  0.499749  \n",
      "37  0.330986  0.335443      1.0  0.499749  \n",
      "38  0.330986  0.335443      1.0  0.499749  \n",
      "39  0.330986  0.335443      1.0  0.499749  \n",
      "40  0.330986  0.335443      1.0  0.499749  \n",
      "41  0.330986  0.335443      1.0  0.499749  \n",
      "42  0.330986  0.335443      1.0  0.499749  \n",
      "43  0.330986  0.335443      1.0  0.499749  \n",
      "44  0.330986  0.335443      1.0  0.499749  \n",
      "45  0.330986  0.335443      1.0  0.499749  \n",
      "46  0.330986  0.335443      1.0  0.499749  \n",
      "47  0.330986  0.335443      1.0  0.499749  \n",
      "48  0.330986  0.335443      1.0  0.499749  \n",
      "49  0.330986  0.335443      1.0  0.499749  \n",
      "100%|██████████| 5/5 [09:53<00:00, 118.61s/trial, best loss: -0.11442983706792195]\n"
     ]
    }
   ],
   "source": [
    "best = fmin(fn=modelize, space=hyperspace, algo=tpe.suggest, max_evals=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4911480-4f5b-4d3b-885e-a02901ba31f8",
   "metadata": {},
   "source": [
    "## comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b64f54b-cb33-4e3e-8b4c-510c03e75e94",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/\n",
      "    run00000/\n",
      "    run00001/\n",
      "        AEMM.jpg\n",
      "        hyperparameters.txt\n",
      "        model_summary.txt\n",
      "        results.plk\n",
      "        val_f1.txt\n",
      "    run00002/\n",
      "        AEMM.jpg\n",
      "        hyperparameters.txt\n",
      "        model_summary.txt\n",
      "        results.plk\n",
      "        val_f1.txt\n",
      "    run00003/\n",
      "        AEMM.jpg\n",
      "        hyperparameters.txt\n",
      "        model_summary.txt\n",
      "        results.plk\n",
      "        val_f1.txt\n",
      "    run00004/\n",
      "        AEMM.jpg\n",
      "        hyperparameters.txt\n",
      "        model_summary.txt\n",
      "        results.plk\n",
      "        val_f1.txt\n",
      "    run00005/\n",
      "        AEMM.jpg\n",
      "        hyperparameters.txt\n",
      "        model_summary.txt\n",
      "        results.plk\n",
      "        val_f1.txt\n",
      "    run00006/\n",
      "        AEMM.jpg\n",
      "        hyperparameters.txt\n",
      "        model_summary.txt\n",
      "        results.plk\n",
      "        val_f1.txt\n",
      "    run00007/\n",
      "        AEMM.jpg\n",
      "        hyperparameters.txt\n",
      "        model_summary.txt\n",
      "        results.plk\n",
      "        val_f1.txt\n",
      "    run00008/\n",
      "        AEMM.jpg\n",
      "        hyperparameters.txt\n",
      "        model_summary.txt\n",
      "        results.plk\n",
      "        val_f1.txt\n",
      "    run00009/\n",
      "        AEMM.jpg\n",
      "        hyperparameters.txt\n",
      "        model_summary.txt\n",
      "        results.plk\n",
      "        val_f1.txt\n"
     ]
    }
   ],
   "source": [
    "def print_directory_structure(root_directory):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "        level = dirpath.replace(root_directory, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(dirpath)))\n",
    "        sub_indent = ' ' * 4 * (level + 1)\n",
    "        for f in filenames:\n",
    "            print('{}{}'.format(sub_indent, f))\n",
    "root_directory = 'runs'\n",
    "print_directory_structure(root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6a78f8d-e38c-4e04-a30c-656c053d43e5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxlist = []\n",
    "runlist = []\n",
    "for run in os.listdir('runs')[1:]:\n",
    "    folderpath = 'runs/'+run\n",
    "    hyperparameters = None\n",
    "    results = None\n",
    "    with open(folderpath+'/results.plk', 'rb') as file:\n",
    "        results = pickle.load(file)\n",
    "    results = results.sort_values(by='val_f1',ascending = False)\n",
    "    maxlist.append(results['val_f1'][0])\n",
    "    runlist.append(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b0fa662-de98-41fa-9934-e9cafda7a18b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({'run':runlist,'f1':maxlist})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f8bcc3b-0def-4a7e-ae9b-ed2f416f6071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comparison = comparison.sort_values(by = 'f1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75f0618d-bcf5-41ab-ad3f-1bd292b17508",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run00003</td>\n",
       "      <td>0.502471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run00004</td>\n",
       "      <td>0.499873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>run00009</td>\n",
       "      <td>0.499749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run00001</td>\n",
       "      <td>0.492204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run00002</td>\n",
       "      <td>0.490110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run00005</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>run00006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>run00007</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>run00008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        run        f1\n",
       "2  run00003  0.502471\n",
       "3  run00004  0.499873\n",
       "8  run00009  0.499749\n",
       "0  run00001  0.492204\n",
       "1  run00002  0.490110\n",
       "4  run00005  0.000000\n",
       "5  run00006  0.000000\n",
       "6  run00007  0.000000\n",
       "7  run00008  0.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4139216-e1e1-4693-8b30-e997bec6bc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
